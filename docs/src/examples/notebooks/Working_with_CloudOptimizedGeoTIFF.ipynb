{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With COG - At Scale\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/developmentseed/titiler/main?filepath=docs%2Fexamples%2F%2Fnotebooks%2FWorking_with_CloudOptimizedGeoTIFF.ipynb)\n",
    "\n",
    "For this demo we will use the new `Ozone Monitoring Instrument (OMI) / Aura NO2 Tropospheric Column Density` dataset hosted on AWS PDS: https://registry.opendata.aws/omi-no2-nasa/\n",
    "\n",
    "Requirement: AWS credentials\n",
    "\n",
    "#### Requirements\n",
    "- AWS credentials\n",
    "- rasterio\n",
    "- folium\n",
    "- httpx\n",
    "- tqdm\n",
    "\n",
    "`!pip install rasterio boto3 folium httpx tqdm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line if you need to install the dependencies\n",
    "# !pip install rasterio boto3 folium requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import urllib.parse\n",
    "from io import BytesIO\n",
    "from functools import partial\n",
    "from concurrent import futures\n",
    "\n",
    "import httpx\n",
    "import numpy\n",
    "from boto3.session import Session as boto3_session\n",
    "\n",
    "from rasterio.plot import reshape_as_image\n",
    "from rasterio.features import bounds as featureBounds\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from folium import Map, TileLayer, GeoJson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titiler_endpoint = \"https://titiler.xyz\"  # Developmentseed Demo endpoint. Please be kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your area of interest (AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use geojson.io\n",
    "geojson = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -74.1796875,\n",
    "              45.18978009667531\n",
    "            ],\n",
    "            [\n",
    "              -73.092041015625,\n",
    "              45.18978009667531\n",
    "            ],\n",
    "            [\n",
    "              -73.092041015625,\n",
    "              46.00459325574482\n",
    "            ],\n",
    "            [\n",
    "              -74.1796875,\n",
    "              46.00459325574482\n",
    "            ],\n",
    "            [\n",
    "              -74.1796875,\n",
    "              45.18978009667531\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "bounds = featureBounds(geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(\n",
    "    tiles=\"OpenStreetMap\",\n",
    "    location=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom_start=6\n",
    ")\n",
    "\n",
    "GeoJson(geojson).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List available files on AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Be able to run this notebook you'll need to have AWS credential available in the environment\n",
    "\n",
    "# import os\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"YOUR AWS ACCESS ID HERE\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"YOUR AWS ACCESS KEY HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3_session(region_name=\"us-west-2\")\n",
    "client = session.client(\"s3\")\n",
    "\n",
    "bucket = \"omi-no2-nasa\"  #https://registry.opendata.aws/omi-no2-nasa/\n",
    "\n",
    "\n",
    "def list_objects(bucket, prefix):\n",
    "    \"\"\"AWS s3 list objects.\"\"\"\n",
    "\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "\n",
    "    files = []\n",
    "    for subset in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        files.extend(subset.get(\"Contents\", []))\n",
    "\n",
    "    return files\n",
    "\n",
    "list_files = list_objects(bucket, \"OMI-Aura_L3\")\n",
    "\n",
    "print(\"Archive Size\")\n",
    "files = [r[\"Key\"] for r in list_files]\n",
    "print(f\"Found {len(files)} OMI-NO2 files\")\n",
    "\n",
    "size = sum([r[\"Size\"]/1000000. for r in list_files])\n",
    "print(f\"Size of the archive: {size} Mo ({size / 1000} Go)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(files[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file name structure is `\"OMI-Aura_L3-OMNO2d_{YEAR}m{MONTH:02}{DAY:02}...\"`\n",
    "\n",
    "We can then easily filter e.g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_2019 = list(filter(lambda x: x.split(\"_\")[2][0:4] == \"2019\", files))\n",
    "print(len(files_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_Oct5 = list(filter(lambda x: (x.split(\"_\")[2][5:7] == \"10\") & (x.split(\"_\")[2][7:9] == \"05\"), files))\n",
    "print(len(files_Oct5))\n",
    "print(files_Oct5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA Endpoint\n",
    "\n",
    "`{endpoint}/cog/tiles/{tileMatrixSetId}/{z}/{x}/{y}.{format}?url={cog}&{otherquery params}`\n",
    "\n",
    "\n",
    "`{endpoint}/cog/bbox/{minx},{miny},{maxx},{maxy}.{format}?url={cog}&{otherquery params}`\n",
    "\n",
    "\n",
    "`{endpoint}/cog/point/{minx},{miny}?url={cog}&{otherquery params}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize One Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _url(src_path):\n",
    "    return f\"s3://omi-no2-nasa/{src_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetch File Metadata to get min/max rescaling values (because the file is stored as float32)\n",
    "\n",
    "r = httpx.get(\n",
    "    f\"{titiler_endpoint}/cog/statistics\",\n",
    "    params = {\n",
    "        \"url\": _url(files[0])\n",
    "    }\n",
    ").json()\n",
    "\n",
    "print(json.dumps(r, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = httpx.get(\n",
    "    f\"{titiler_endpoint}/cog/WebMercatorQuad/tilejson.json\",\n",
    "    params = {\n",
    "        \"url\": _url(files[2]),\n",
    "        \"rescale\": \"0,3000000000000000\",\n",
    "        \"colormap_name\": \"viridis\",\n",
    "    }\n",
    ").json()\n",
    "\n",
    "m = Map(\n",
    "    location=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom_start=6\n",
    ")\n",
    "\n",
    "TileLayer(\n",
    "    tiles=r[\"tiles\"][0],\n",
    "    opacity=1,\n",
    "    attr=\"NASA\"\n",
    ").add_to(m)\n",
    "\n",
    "GeoJson(geojson, style_function=lambda feature: {\"fill\": False, \"color\": \"red\"}).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create time series of NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stats(data, mask):\n",
    "    arr = numpy.ma.array(data)\n",
    "    arr.mask = mask == 0\n",
    "    return arr.min().item(), arr.max().item(), arr.mean().item(), arr.std().item()\n",
    "\n",
    "\n",
    "xmin, ymin, xmax, ymax = bounds\n",
    "\n",
    "def fetch_bbox(file):\n",
    "    url = f\"{titiler_endpoint}/cog/bbox/{xmin},{ymin},{xmax},{ymax}.npy\"\n",
    "    params = {\n",
    "        \"url\": _url(file),\n",
    "        \"bidx\": \"1\",\n",
    "        \"max_size\": 128,\n",
    "    }\n",
    "    r = httpx.get(url, params=params)\n",
    "    data = numpy.load(BytesIO(r.content))\n",
    "    s = _stats(data[0:-1], data[-1])\n",
    "    return (\n",
    "        _stats(data[0:-1], data[-1]),\n",
    "        datetime.datetime.strptime(file.split(\"_\")[2].replace(\"m\", \"\"), \"%Y%m%d\"),\n",
    "    )\n",
    "\n",
    "# small tool to filter invalid response from the API\n",
    "def _filter_futures(tasks):\n",
    "    for future in tasks:\n",
    "        try:\n",
    "            yield future.result()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NO2 Max for day 15th of each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every 15 of each month for all the years\n",
    "files_15 = list(filter(lambda x: (x.split(\"_\")[2][7:9] == \"15\"), files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_work = [\n",
    "        executor.submit(fetch_bbox, file) for file in files_15\n",
    "    ]\n",
    "\n",
    "    for f in tqdm(futures.as_completed(future_work), total=len(future_work)):\n",
    "        pass\n",
    "\n",
    "values, dates  = zip(*list(_filter_futures(future_work)))\n",
    "\n",
    "max_values = [\n",
    "    v[1]\n",
    "    for v in values\n",
    "]\n",
    "\n",
    "fig, ax1 = plt.subplots(dpi=300)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "ax1.plot(dates, max_values, label=\"No2\")\n",
    "ax1.xaxis.set_major_locator(mdates.YearLocator(1,7))\n",
    "\n",
    "ax1.set_xlabel(\"Dates\")\n",
    "ax1.set_ylabel(\"No2\")\n",
    "\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same but for all the days for the last 16 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with futures.ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    future_work = [\n",
    "        executor.submit(fetch_bbox, file) for file in files\n",
    "    ]\n",
    "\n",
    "    for f in tqdm(futures.as_completed(future_work), total=len(future_work)):\n",
    "        pass\n",
    "\n",
    "values, dates  = zip(*list(_filter_futures(future_work)))\n",
    "\n",
    "max_values = [\n",
    "    v[1]\n",
    "    for v in values\n",
    "]\n",
    "\n",
    "fig, ax1 = plt.subplots(dpi=150)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "ax1.plot(dates, max_values, label=\"No2\")\n",
    "ax1.xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "ax1.set_xlabel(\"Dates\")\n",
    "ax1.set_ylabel(\"No2\")\n",
    "\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
